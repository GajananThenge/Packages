https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6
https://keras.io/
https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32
https://www.google.com/search?q=inception+transfer+learning&rlz=1C1GCEV_enIN846IN846&oq=inception+tr&aqs=chrome.2.69i57j0l5.9392j0j7&sourceid=chrome&ie=UTF-8
https://becominghuman.ai/transfer-learning-retraining-inception-v3-for-custom-image-classification-2820f653c557
https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a


1.Keras
	1. Core data structure is model.
	2. Simplest way of model is Sequential model(linear stack of Layer)
	3. It will used Tensor flow at backend for processing.
	
	Installation:
	Note: Before installing Keras, please install one of its backend engines: TensorFlow, Theano, or CNTK.
	We recommend the TensorFlow backend.
	
	
	Keras was initially developed as part of the research effort of 
	project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot 
	Operating System).
	
	You Can install option dependencies:
		1.	cuDNN (Required whwn running Keras on GPU)
		2.	HDF5 amd h5dy (Required to save Kears model on disk)
		graphviz and pydot (used by visualisation utilities) to plot model graphs.
		
	Deep Learning Framework
	A deep learning framework is an interface, library or a tool 
	which allows us to build deep learning models more easily and 
	quickly, without getting into the details of underlying 
	algorithms. 
	
	With Keras
	https://towardsdatascience.com/building-your-own-artificial-neural-network-from-scratch-on-churn-modeling-dataset-using-keras-in-690782f7d051
	# ANN
	Listing out the steps involved in training the ANN with Stochastic Gradient Descent:-
	1)Randomly initialize the weights to small numbers close to 0(But not 0).
	2)Input the 1st observation of your dataset in the Input Layer, each Feature in one Input Node.
	3)Forward-Propagation from Left to Right, the neurons are activated in a way that the impact of each neuron’s activation.
	is limited by the weights.Propagate the activations until getting the predicted result y.
	4)Compare the predicted result with the actual result. Measure the generated error.
	5)Back-Propagation: From Right to Left, Error is back propagated.Update the weights according to how much they are
	responsible for the error.The Learning Rate tells us by how much such we update the weights.
	6)Repeat Steps 1 to 5 and update the weights after each observation(Reinforcement Learning).
	Or: Repeat Steps 1 to 5 but update the weights only after a batch of observations(Batch Learning).
	7)When the whole training set is passed through the ANN.That completes an Epoch. Redo more Epochs.

		
	Importing the Keras libraries and packages
	import keras
	For building the Neural Network layer by layer

	from keras.models import Sequential
	To randomly initialize the weights to small numbers close to 0(But not 0)

	from keras.layers import Dense
	Initializing the ANN…
	So there are actually 2 ways of initializing a deep learning model
	— — — 1)Defining each layer one by one
	— — — 2)Defining a Graph

	We did not put any parameter in the Sequential object as we will be defining the Layers manually

	classifier = Sequential()
	Adding the input layer and the first hidden layer…
	This remains an unanswered question till date that how many nodes of the hidden layer do we actually need?
	There is no thumb rule but you can set the number of nodes in Hidden Layers as an Average of the number of Nodes in Input and Output Layer Respectively.(Works in 90% of the cases!!)
	 — →Here avg= (11+1)/2==>6 So set Output Dim=6
	 — →Init will initialize the Hidden Layer weights uniformly
	 — →Activation Function is Rectifier Activation Function(Relu)

	Input dim tells us the number of nodes in the Input Layer.This is done only once and wont be specified in further layers.

	classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))
	### Adding the second hidden layer…
	classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))
	
	### Adding the output layer…
	classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))
	
	#Sigmoid activation function is used whenever we need Probabilities of 2 categories or less(Similar to Logistic Regression)
	Switch to Softmax when the dependent variable has more than 2 categories.

	### Compiling the ANN…
	classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
	
	###Fitting the ANN to the Training set
	classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)
	
	### Part 3 — Making the predictions and evaluating the model
	Predicting the Test set results

	y_pred = classifier.predict(X_test)
	y_pred = (y_pred > 0.5)
	if y_pred is larger than 0.5 it returns true(1) else false(2)

	print(y_pred)
	This Model when trained on the train data and when tested on the test data gives us an accuracy of around 86% in both of the cases.Which from our point of view is Great!!!

	Making the Confusion Matrix

	from sklearn.metrics import confusion_matrix
	cm = confusion_matrix(y_test, y_pred)
	print(cm)
	Obtained from Confusion Matrix.You may change values as per what is obtained in your confusion matrix.

	print(accuracy)
	
	#CNN
	http://jtaken.csoft.net/book/Deep%20Learning%20with%20Python%20-%20A%20Hands-on%20Introduction%20-%201E%20(2017)%20(Pdf)%20Gooner/
	https://www.analyticsvidhya.com/blog/2016/10/tutorial-optimizing-neural-networks-using-keras-with-image-recognition-case-study/
	1.Convolutional neural networks or also called convnets
	2.They have revolutionized image classification and computer vision by being 
	able to extract features from images and using them in neural networks. 
	3.You can imagine a CNN as a specialized neural network that is able to detect specific patterns.
	4.How it is different that Neural Network?
		1.A CNN has hidden layers which are called convolutional layers. 
		2.For computer image is nothing but two dimentinal matrix of numbers,so there should be some mechanism to extract features 
		  out of these matrics.
		3.These convolutional layers are able to detect edges, corners and other kinds of textures which makes them such a special tool. 
		The convolutional layer consists of multiple filters which are slid across the image and are able to detect specific features.
		4. With each convolutional layer the network is able to detect more complex patterns. 
	https://www.slideshare.net/KirillEremenko/deep-learning-az-convolutional-neural-networks-cnn-module-2
	
	
	Terminologies
	https://heartbeat.fritz.ai/a-beginners-guide-to-convolutional-neural-networks-cnn-cf26c5ee17ed
	https://blog.xrds.acm.org/2016/06/convolutional-neural-networks-cnns-illustrated-explanation/
	Steps in convolution:
	1. Convolution
		A convolution is a combined integration of two functions that shows you how one function modifies the other.
		It consist of important term : the input image, the feature detector, and the feature map
		Input Image: 
		 The aim of this step is to reduce the size of the image and make processing faster and easier. 
		 Some of the features of the image are lost in this step but at same time important features will be retained.
		 These features are unique in nature to identify specific object.
	
	2. Pooling
	https://www.edureka.co/blog/convolutional-neural-network/
		In this layer we shrink the image stack into a smaller size. Pooling is done after passing through the activation layer. 
		We do this by implementing the following 4 steps:
		Pick a window size (usually 2 or 3)
		Pick a stride (usually 2)
		Walk your window across your filtered images
		From each window, take the maximum value.
	3. Flattenning
		Once the pooled featured map is obtained, the next step is to 
		flatten it. Flattening involves transforming the entire pooled 
		feature map matrix into a single column which is then fed 
		to the neural network for processing.
		
	4. Full Connection
	CNN image
	https://www.learnopencv.com/keras-tutorial-transfer-learning-using-pre-trained-models/
	
	
	### Implement using Keras
	You have different convolutional layers available in Keras:
		1.Conv1D
			1D convolutional layer.
			This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) 
			dimension to produce a tensor of outputs
		2. Conv2D
			2D convolution layer (e.g. spatial convolution over images).
			
	
	
	
	
	
	#RNN
	https://adventuresinmachinelearning.com/keras-lstm-tutorial/
	https://www.analyticsvidhya.com/blog/2017/12/introduction-to-recurrent-neural-networks/
	1.A recurrent neural network is a neural network that 
	attempts to model time or sequence dependent behaviour – such 
	as language, stock prices, electricity demand and so on.
	
	
	
	index of: Deep Learnining with Python
	https://rubikscode.net/2018/03/26/two-ways-to-implement-lstm-network-using-python-with-tensorflow-and-keras/
	https://rubikscode.net/2018/02/19/artificial-neural-networks-series/
	
	#How Python Code Executes
	https://indianpythonista.wordpress.com/2018/01/04/how-python-runs/
	
	
	
	
	
	#Transfer Learning
	https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a
	https://towardsdatascience.com/keras-transfer-learning-for-beginners-6c9b8b7143e
	https://machinelearningmastery.com/transfer-learning-for-deep-learning/
	https://www.pyimagesearch.com/2019/05/20/transfer-learning-with-keras-and-deep-learning/
	http://cs231n.github.io/transfer-learning/
	
	
	Humans have inherent ability to transfer /aplly knowleged across similar kind of taks.
	Ex.Who know how to ride bicyle ---> can learn to drive Scooter/bike
		
	The more related task ,it is easy for us to transfer, or cross-utilize our knowledge.
	In above example, learning process of scooter driving has not started from scrath.
	
	In each of the above scenarios, we don’t learn everything from 
	scratch when we attempt to learn new aspects or topics. 
	We transfer and leverage our knowledge from what we have learnt 
	in the past!
	
	Traditional learning is isolated and occurs purely based on 
	specific tasks, datasets and training separate isolated models
	on them. No knowledge is retained which can be transferred 
	from one model to another. In transfer learning, you can 
	leverage knowledge (features, weights etc) from previously 
	trained models for training newer models and even tackle 
	problems like having less data for the newer task!
	
	
	Traditional supervised ML algorithms break down when we do not 
	have sufficient training examples for the required tasks in given 
	domains.
	
	The advantages of transfer learning are that:

	1: There is no need of an extremely large training dataset.

	2: Not much computational power is required.As we are using 
	pre-trained weights and only have to learn the weights of the 
	last few layers.
	
	https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	Generator
A generator expression does not create the full list in memory, but creates an iterator objects. This iterator is lazy and will create the items on demand. When 
Iterator.

A generator is a function that returns an object (iterator) which we can iterate over (one value at a time).

A generator expression can possibly save a lot of memory and be more efficient
Generator expressions can only be iterated once and cannot be accessed by index

How to create a generator in Python?
It is as easy as defining a normal function with yield statement instead of a return statement.

Advantages of Generator:
1. Easy to implement
2. Memory efficient
3. Represent Infinite Stream



Differences between Generator function and a Normal function?

Ex.
https://www.programiz.com/python-programming/generator
# A simple generator function
def my_gen():
    n = 1
    print('This is printed first')
    # Generator function contains yield statements
    yield n

    n += 1
    print('This is printed second')
    yield n

    n += 1
    print('This is printed at last')
    yield n

	
# Iterator
https://www.programiz.com/python-programming/iterator#infinite
Iterators are objects that can be iterated upon.
Returns one element at a time.	

https://www.programiz.com/python-programming/iterator
	
	


Map,filter,Reduce

Map:
syntax: map(f,iterator)
Its LAzy in Python

To get the 10 first even numbers, with map you can write: evens = map(lambda n: n*2, range(10)).

When all you’re doing is calling an already-defined function on each element, map(f, lst) is a little faster than the corresponding list comprehension 
[f(x) for x in lst]. To an experienced Python 




Comprehensions:
https://courses.cs.washington.edu/courses/cse140/14wi/lectures/22-list-comprehensions.pdf

List Comprehensions:
1.Enables you to transform a list into another list
2.The syntax for generator expression is similar to that of a list comprehension in Python. But the square brackets are replaced with round parentheses.


When Not To Used:

1.You cannot use list comprehensions when the construction rule is too complicated to be expressed with "for" and "if" statements, 
or if the construction rule can change dynamically at runtime. In this case, you better use map() and / or filter() with an 
appropriate function. Of course, you can combine that with list comprehensions.

2. Based on a specific condition, if you want to break out of the LC, during iteration, it is NOT possible at all. Though it uses for loop, 
break, continue and other looping related stuff will not be available.


Python Generator Expression
my_list = [1,2,5,3,8,9]
(x**2 for x in my_list)


The major difference between a list comprehension and a generator expression is that while list 
comprehension produces the entire list, generator expression produces one item at a time.


https://www.machinelearningplus.com/python/list-comprehensions-in-python/

Functions:
1.function is a piece of code written to carry out a specified task.
2. Inputs to function: Arguments
3. It may or may not return values
4. Parameters: names used when defining a function or a method, and into which arguments will be mapped
5. Arguments :  argument is a value that is passed to the function when it's called
6.  while the function or method code refers to the arguments by their parameter names.
7.  functions immediately exit when they come across a return statement

Function Arguments in Python:
Default arguments: 
 take a default value if no argument value is passed during the function call.
		ex. def plus(a,b = 2):
		  return a + b
		  
		# Call `plus()` with only `a` parameter
		plus(a=1)

		# Call `plus()` with `a` and `b` parameters
		plus(a=1, b=3)

Required arguments:
Required arguments are the arguments passed to a function in correct positional order.

Keyword arguments:
to make sure that you call all the parameters in the right order, you can use the keyword arguments in your function call.
Variable number of arguments


what is __name__ == '__main__'?
When a python program is executed, python interpreter starts executing code inside it. It also sets few implicit variable values, one of them is __name__ whose value is set as __main__.
For python main function, we have to define a function and then use if __name__ == '__main__' condition to execute this function.
Scope and Lifetime of variables
Local and Global

Variables that are defined inside a function body have a local scope, and those defined outside have a global scope.










''' Program to transpose a matrix using list comprehension'''


X = [[12,7],
    [4 ,5],
    [3 ,8]]

result = [[X[j][i] for j in range(len(X))] for i in range(len(X[0]))]

for r in result:
   print(r)
	
		
